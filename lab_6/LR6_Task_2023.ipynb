{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d18bc367",
   "metadata": {},
   "source": [
    "# Лабораторная работа №8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ff9391",
   "metadata": {},
   "source": [
    "## Метод главных компонент"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e71353d",
   "metadata": {},
   "source": [
    "### Задание 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2390317d",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6ae44c",
   "metadata": {},
   "source": [
    "1. Используя данные для цветков ириса произвести уменьшение размерности данных с помощью метода главных компонет. Реализовать собственный алгоритм, а также использовать встроенный.\n",
    "2. Оценить степень потери данных. \n",
    "3. Выберите оптимальное количество компонент в новых данных. \n",
    "4. Протестируйте точность различных алгоритмов классификации на исходном датасете и на преобразованном с помощью метода главных компонент. Дайте подробные выводы о различных комбинациях числа компонет и алгоритмах. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class CustomPCA:\n",
    "    def __init__(self, n_components:int):\n",
    "        self.n_components = n_components\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        mean_vals = np.mean(X, axis=0)\n",
    "        centered_data = X - mean_vals\n",
    "        cov_matrix = np.cov(centered_data, rowvar=False)\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
    "        sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "        top_indices = sorted_indices[:self.n_components]\n",
    "        pca_result = centered_data.dot(eigenvectors[:, top_indices])\n",
    "        self.eigenvalues = eigenvalues\n",
    "        self.top_indices = top_indices\n",
    "        return pca_result\n",
    "\n",
    "# Применение собственного алгоритма PCA к данным ириса\n",
    "cust_pca = CustomPCA(2)\n",
    "X_custom_pca = cust_pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Собственный алгоритм PCA: Объясненная дисперсия при 1 компонент - 0.9246\n",
      "Собственный алгоритм PCA: Объясненная дисперсия при 2 компонент - 0.9777\n",
      "Собственный алгоритм PCA: Объясненная дисперсия при 3 компонент - 0.9948\n",
      "Собственный алгоритм PCA: Объясненная дисперсия при 4 компонент - 1.0000\n"
     ]
    }
   ],
   "source": [
    "for i in [1,2,3,4]:\n",
    "    cust_pca = CustomPCA(i)\n",
    "    X_custom_pca = cust_pca.fit_transform(X)\n",
    "    explained_variance_ratio_custom = np.sum(cust_pca.eigenvalues[cust_pca.top_indices]) / np.sum(cust_pca.eigenvalues)\n",
    "    print(f\"Собственный алгоритм PCA: Объясненная дисперсия при {i} компонент - {explained_variance_ratio_custom:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Встроенный PCA: Объясненная дисперсия при 1 компонент- 0.9246\n",
      "Встроенный PCA: Объясненная дисперсия при 2 компонент- 0.9777\n",
      "Встроенный PCA: Объясненная дисперсия при 3 компонент- 0.9948\n",
      "Встроенный PCA: Объясненная дисперсия при 4 компонент- 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "for i in [1,2,3,4]:\n",
    "    pca = PCA(n_components=i)\n",
    "    X_builtin_pca = pca.fit_transform(X)\n",
    "    explained_variance_ratio_builtin = np.sum(pca.explained_variance_ratio_)\n",
    "    print(f\"Встроенный PCA: Объясненная дисперсия при {i} компонент- {explained_variance_ratio_builtin:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_builtin_pca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/natalliazzz/miniconda3/envs/ds_labs/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходные данные:\n",
      "Logistic Regression: 0.9733\n",
      "K-Nearest Neighbors: 0.9733\n",
      "Decision Tree: 0.9533\n",
      "\n",
      "PCA данные:\n",
      "Logistic Regression: 0.9600\n",
      "K-Nearest Neighbors: 0.9667\n",
      "Decision Tree: 0.9200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Исходные данные\n",
    "lr_original = LogisticRegression()\n",
    "knn_original = KNeighborsClassifier()\n",
    "dt_original = DecisionTreeClassifier()\n",
    "\n",
    "# Преобразованные данные\n",
    "lr_pca = LogisticRegression()\n",
    "knn_pca = KNeighborsClassifier()\n",
    "dt_pca = DecisionTreeClassifier()\n",
    "\n",
    "# Точность на исходных данных\n",
    "acc_lr_original = cross_val_score(lr_original, X, y, cv=5, scoring='accuracy').mean()\n",
    "acc_knn_original = cross_val_score(knn_original, X, y, cv=5, scoring='accuracy').mean()\n",
    "acc_dt_original = cross_val_score(dt_original, X, y, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "# Точность на данных после PCA\n",
    "acc_lr_pca = cross_val_score(lr_pca, X_builtin_pca, y, cv=5, scoring='accuracy').mean()\n",
    "acc_knn_pca = cross_val_score(knn_pca, X_builtin_pca, y, cv=5, scoring='accuracy').mean()\n",
    "acc_dt_pca = cross_val_score(dt_pca, X_builtin_pca, y, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "# Вывод результатов\n",
    "print(\"Исходные данные:\")\n",
    "print(f\"Logistic Regression: {acc_lr_original:.4f}\")\n",
    "print(f\"K-Nearest Neighbors: {acc_knn_original:.4f}\")\n",
    "print(f\"Decision Tree: {acc_dt_original:.4f}\")\n",
    "print(\"\\nPCA данные:\")\n",
    "print(f\"Logistic Regression: {acc_lr_pca:.4f}\")\n",
    "print(f\"K-Nearest Neighbors: {acc_knn_pca:.4f}\")\n",
    "print(f\"Decision Tree: {acc_dt_pca:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f2d158",
   "metadata": {},
   "source": [
    "### Задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ecaea5",
   "metadata": {},
   "source": [
    "1. Используя данные о клиентах сотового оператора (telecom.csv) произвести уменьшение размерности данных с помощью метод главных компонет. Реализовать собственный алгоритм, а также использовать встроенный.\n",
    "2. Оценить степень потери данных. \n",
    "3. Выберите оптимальное количетсво компонент в новых данных. \n",
    "4. Протестируйте точность различных алгоритмов классификации на исходном датасете и на преобразованном с помощью метода главных компонент. Дайте подробные выводы о различных комбинациях числа компонет и алгоритмах. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f81973",
   "metadata": {},
   "source": [
    "### Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cbdd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2169572",
   "metadata": {},
   "source": [
    "1. Используя данные о рукописных цифрах произвести уменьшение размерности данных с помощью метода главных компонет.Реализовать собственный алгоритм, а также использовать встроенный.\n",
    "2. Оценить степень потери данных. \n",
    "3. Выберите оптимальное колиечество компонент в новых данных. \n",
    "4. Протестируйте точность различных алгоритмов классификации на исходном датасете и на преобразованном с помощью метода главных компонент. Дайте подробные выводы о различных комбинациях числа компонет и алгоритмах. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30371461",
   "metadata": {},
   "source": [
    "### Задание 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4ac7bf",
   "metadata": {},
   "source": [
    "Вычислениями подвердите связь сингулярного разложения матрицы с методом главных компонент. Приведите практический пример."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284a5523",
   "metadata": {},
   "source": [
    "## Полезные ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25545ae",
   "metadata": {},
   "source": [
    "1. [Хорошая статья на русском о PCA](https://habr.com/ru/post/304214/)\n",
    "2. [sklearn PCA doc](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)\n",
    "3. [Выбор количества компонент](https://www.mikulskibartosz.name/pca-how-to-choose-the-number-of-components/)\n",
    "4. [PCA через сингулярное разложение](https://towardsdatascience.com/pca-and-svd-explained-with-numpy-5d13b0d2a4d8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
